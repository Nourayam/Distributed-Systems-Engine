# RAFT DSS â€” A Production-Grade Distributed Systems Engine

## Problem
Understanding distributed consensus algorithms like RAFT requires hands-on experimentation with leader election, log replication, and network partition scenariosâ€”but most educational resources offer only theoretical explanations.  
Real-world distributed systems engineers need practical experience with fault-tolerance, message-passing semantics, and consensus behaviour under realistic network conditions.

## Solution
This RAFT simulator provides a comprehensive, event-driven environment for exploring distributed consensus from the ground up:

- **Pure Python Implementation:** RAFT consensus algorithm built from scratch with full state machine semantics  
- **Realistic Network Simulation:** configurable latency, packet loss, and partition injection  
- **High-Performance Event Engine:** processes thousands of consensus events per second with microsecond precision  
- **Production-Grade Architecture:** modular design supporting algorithm swapping and extensibility

## Core Features

- **Complete RAFT Implementation:** leader election, log replication, term management, and follower synchronisation  
- **Network Fault Injection:** message drops, delays, duplicates, and network partitions with statistical modelling  
- **Event-Driven Simulation:** priority-queue scheduling with deterministic replay and comprehensive logging  
- **Configurable Cluster Topologies:** support for 3â€“100+ node clusters with dynamic failure scenarios  
- **Rich Observability:** detailed state tracking, message tracing, and consensus timeline reconstruction  
- **Chaos Engineering:** automated failure injection patterns including rolling failures and split-brain scenarios

## System Architecture

The simulator follows a clean event-driven pipeline:

- `simulation/` â€” priority-queue event scheduler with microsecond timing  
- `nodes/` â€” RAFT state machines with leader election and log replication  
- `messaging/` â€” realistic network simulation with configurable failure modes  
- `failure/` â€” chaos engineering toolkit for testing fault-tolerance  
- `config.py` â€” centralised tuning for network conditions and cluster behaviour  

Each layer operates independently, enabling modular testing and algorithm experimentation.

## Setup & Running

**Prerequisites:** Python 3.9+ (standard library only)

```bash
# Clone and enter project directory
git clone https://github.com/yourusername/raft-simulator.git
cd raft-simulator

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Run basic simulation
python main.py --nodes 5 --max_time 60

# Run with chaos testing
python main.py --nodes 5 --chaos --chaos_scenario leader_failure

# Adjust network conditions
python main.py --nodes 7 --message_drop_rate 0.05 --max_time 120


## ðŸ“Š Examples

### Basic Consensus Demonstration

```bash
$ python main.py --nodes 5 --max_time 30

============================================================
SIMULATION RESULTS
============================================================
Node ID  State      Term   Alive  Log Size
------------------------------------------------------------
0        FOLLOWER   5      1      0  
1        FOLLOWER   5      1      0  
2        FOLLOWER   5      1      0  
3        FOLLOWER   5      1      0  
4        LEADER     5      1      0  

Leader: 4  
Leader term: 5  

Simulation Statistics:
Events processed: 2,128  
Simulation time: 30.15 seconds  
Node states: {'FOLLOWER': 4, 'LEADER': 1}  
Alive nodes: 5/5

Technical Highlights

- Performance: Processes 100+ consensus events per millisecond with deterministic ordering  
- Accuracy: Implements complete RAFT specification with readiness for log compaction  
- Extensibility: Designed to accommodate Paxos, Byzantine fault tolerance, or custom protocols  
- Testing: Comprehensive failure scenarios validate edge cases and recovery pathways

---

Future Development

- Web Dashboard: Interactive consensus state visualisation via React or PyQt  
- Algorithm Extensions: Multi-RAFT, Paxos, and Byzantine fault-tolerant implementations  
- Benchmarking Suite: Compare performance across algorithms and configurations  
- Distributed Deployment: Enable multi-host execution for real-world topology simulation

